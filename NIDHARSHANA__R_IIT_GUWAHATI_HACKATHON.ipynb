{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO34zJNCJ/TPMvFDi3wqlvd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nidharshana0325/NIDHI-IIT-GUWAHATI-DATAHACK/blob/main/NIDHARSHANA__R_IIT_GUWAHATI_HACKATHON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load training set features and labels from CSV\n",
        "train_features = pd.read_csv('training_set_features.csv')\n",
        "train_labels = pd.read_csv('training_set_labels.csv')\n",
        "\n",
        "# Load test set features from CSV\n",
        "test_features = pd.read_csv('test_set_features.csv')\n",
        "\n",
        "# Merge training features and labels\n",
        "train_df = pd.merge(train_features, train_labels, on='respondent_id')\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = ['age_group', 'education', 'race', 'sex', 'income_poverty',\n",
        "                    'marital_status', 'rent_or_own', 'employment_status',\n",
        "                    'hhs_geo_region', 'census_msa', 'employment_industry',\n",
        "                    'employment_occupation']\n",
        "\n",
        "# Identify numerical columns\n",
        "numerical_cols = [col for col in train_df.columns if col not in categorical_cols + ['respondent_id', 'xyz_vaccine', 'seasonal_vaccine']]\n",
        "\n",
        "# Define transformers for preprocessing\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(drop='first'))\n",
        "])\n",
        "\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply preprocessing to the training data\n",
        "X = train_df.drop(['respondent_id', 'xyz_vaccine', 'seasonal_vaccine'], axis=1)\n",
        "y_xyz = train_df['xyz_vaccine']\n",
        "y_seasonal = train_df['seasonal_vaccine']\n",
        "\n",
        "X_encoded = preprocessor.fit_transform(X)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train_xyz, y_val_xyz = train_test_split(X_encoded, y_xyz, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train_seasonal, y_val_seasonal = train_test_split(X_encoded, y_seasonal, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize logistic regression models\n",
        "model_xyz = LogisticRegression(max_iter=1000)\n",
        "model_seasonal = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Fit models\n",
        "model_xyz.fit(X_train, y_train_xyz)\n",
        "model_seasonal.fit(X_train, y_train_seasonal)\n",
        "\n",
        "# Predict probabilities for validation set\n",
        "pred_proba_xyz_val = model_xyz.predict_proba(X_val)[:, 1]\n",
        "pred_proba_seasonal_val = model_seasonal.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Calculate ROC AUC scores for validation set\n",
        "auc_xyz = roc_auc_score(y_val_xyz, pred_proba_xyz_val)\n",
        "auc_seasonal = roc_auc_score(y_val_seasonal, pred_proba_seasonal_val)\n",
        "\n",
        "print(f'ROC AUC for xyz_vaccine: {auc_xyz:.4f}')\n",
        "print(f'ROC AUC for seasonal_vaccine: {auc_seasonal:.4f}')\n",
        "\n",
        "# Apply preprocessing to the test data\n",
        "X_test = test_features.drop(['respondent_id'], axis=1)\n",
        "X_test_encoded = preprocessor.transform(X_test)\n",
        "\n",
        "# Predict probabilities for test set\n",
        "pred_proba_xyz_test = model_xyz.predict_proba(X_test_encoded)[:, 1]\n",
        "pred_proba_seasonal_test = model_seasonal.predict_proba(X_test_encoded)[:, 1]\n",
        "\n",
        "# Prepare submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'respondent_id': test_features['respondent_id'],\n",
        "    'xyz_vaccine': pred_proba_xyz_test,\n",
        "    'seasonal_vaccine': pred_proba_seasonal_test\n",
        "})\n",
        "\n",
        "# Save submission file\n",
        "submission_df.to_csv('submission_format.csv', index=False)\n",
        "\n",
        "print(\"Submission saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa3w889VzUNg",
        "outputId": "4c6f4a9d-86ae-4f85-aba6-91ecb99dec61"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC for xyz_vaccine: 0.8344\n",
            "ROC AUC for seasonal_vaccine: 0.8564\n",
            "Submission saved successfully.\n"
          ]
        }
      ]
    }
  ]
}